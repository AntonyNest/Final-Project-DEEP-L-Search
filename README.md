# Final-Project-DEEP-L-Search

## Description
The goal of the project is to implement a contextual search service. The service should be able to search for relevant documents based on the user's query. The service should be able to handle a large number of documents and should be able to handle a large number of queries.

An intelligent document search system that uses modern machine learning technologies for semantic analysis and content search in .docx, .doc, .pdf format documents.

üß† Semantic Search: Understands context and synonyms, not just exact matches
üá∫üá¶ Ukrainian Language Support: Optimized for working with Ukrainian texts
üìÑ Multiple formats: .docx, .doc, .pdf documents
‚ö° Quick Search: Vector search using Qdrant
üîß REST API: Ready endpoints for integration
üê≥ Docker Ready: Full containerization for easy deployment
üìä Analytics: Detailed statistics and monitoring

## System Architecture
Our system will consist of four main components:
Document Processor - processing .doc/.docx files and text extraction
Embedding Service - generation of vector representations of text
Vector Database (Qdrant) - storage of embeddings and metadata
Search API - REST API for searching and interacting with the system

graph TD
    A[Documents] --> B[Document Processor]
    B --> C[Text Extraction]
    C --> D[Text Chunking]
    D --> E[Embedding Service]
    E --> F[Vector Database<br/>Qdrant]
    
    G[User Query] --> H[Search API]
    H --> E
    E --> I[Vector Search]
    F --> I
    I --> J[Post-processing]
    J --> K[Search Results]
    
    style E fill:#e1f5fe
    style F fill:#f3e5f5
    style H fill:#e8f5e8

## Prerequisites

Python 3.11+

Docker and Docker Compose
Minimum 4GB RAM
GPU (optional, for acceleration)

1. Cloning the repository
git clone https://github.com/AntonyNest/Final-Project-DEEP-L-Search.git
cd DOCUMENTS_PATH-search-service

2. Environment setup
### –ö–æ–ø—ñ—é—î–º–æ –ø—Ä–∏–∫–ª–∞–¥ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—ó
cp .env.example .env

### –†–µ–¥–∞–≥—É—î–º–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é –ø—ñ–¥ –≤–∞—à—ñ –ø–æ—Ç—Ä–µ–±–∏
nano .env

DOCUMENTS_PATH="C:\\Users\\YourName\\Documents\\MyDocs"

3. Run through Docker Compose
### –ó–∞–ø—É—Å–∫ –≤—Å—ñ—Ö —Å–µ—Ä–≤—ñ—Å—ñ–≤
docker-compose up -d

### –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å—É
docker-compose ps

### –ü–µ—Ä–µ–≥–ª—è–¥ –ª–æ–≥—ñ–≤
docker-compose logs -f document-search-api

4. Local launch
### –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤—ñ—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
python -m venv venv
source venv/bin/activate  # Linux/Mac or venv\Scripts\activate     # Windows

### –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π
pip install -r requirements.txt

### –ó–∞–ø—É—Å–∫ Qdrant (–æ–∫—Ä–µ–º–æ)
docker run -p 6333:6333 qdrant/qdrant

### –ó–∞–ø—É—Å–∫ –¥–æ–¥–∞—Ç–∫—É
python -m uvicorn app.main:app --reload

5. Checking the work
–í—ñ–¥–∫—Ä–∏–π—Ç–µ —É –±—Ä–∞—É–∑–µ—Ä—ñ:

API Documentation: http://localhost:8000/docs
Health Check: http://localhost:8000/health
Qdrant Dashboard: http://localhost:6333/dashboard

### –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è API
#### Indexing –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
–°–ø–æ—á–∞—Ç–∫—É –ø–æ—Ç—Ä—ñ–±–Ω–æ –ø—Ä–æ—ñ–Ω–¥–µ–∫—Å—É–≤–∞—Ç–∏ –≤–∞—à—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏:

curl -X POST "http://localhost:8000/api/v1/documents/index" \
  -H "Content-Type: application/json" \
  -d '{
    "custom_path": "/path/to/your/documents",
    "force_reindex": false
  }'

#### –°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –ø–æ—à—É–∫

curl -X POST "http://localhost:8000/api/v1/search/semantic" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "—ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ–π–Ω–µ –∑–∞–±–µ–∑–ø–µ—á–µ–Ω–Ω—è —Å–∏—Å—Ç–µ–º–∏ —É–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è",
    "limit": 10,
    "score_threshold": 0.7,
    "include_stats": true
  }'

#### –®–≤–∏–¥–∫–∏–π –ø–æ—à—É–∫ (GET)

curl "http://localhost:8000/api/v1/search/quick?q=–∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞%20—Å–∏—Å—Ç–µ–º–∏&limit=5"

#### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º–∏

curl "http://localhost:8000/api/v1/search/stats"

### Configuration
–û—Å–Ω–æ–≤–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏

DOCUMENTS_PATH- –®–ª—è—Ö –¥–æ –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ (–æ–±–æ–≤'—è–∑–∫–æ–≤–æ)
QDRANT_HOST- –•–æ—Å—Ç Qdrant (localhost)
EMBEDDING_MODEL - ML –º–æ–¥–µ–ª—å (paraphrase-multilingual-MiniLM-L12-v2)
MAX_CHUNK_SIZE - –†–æ–∑–º—ñ—Ä —Ñ—Ä–∞–≥–º–µ–Ω—Ç—É (1000) 
SIMILARITY_THRESHOLD - –ü–æ—Ä—ñ–≥ —Å—Ö–æ–∂–æ—Å—Ç—ñ (0.5)

### ML –º–æ–¥–µ–ª—å –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
–î–ª—è –∫—Ä–∞—â–æ—ó —Ä–æ–±–æ—Ç–∏ –∑ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é:

#### –ë–∞–ª–∞–Ω—Å–æ–≤–∞–Ω–∞ –º–æ–¥–µ–ª—å (—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ)
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

#### –í–∏—â–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å (–ø–æ–≤—ñ–ª—å–Ω—ñ—à–µ)
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-mpnet-base-v2

#### –®–≤–∏–¥—à–∞ —Ä–æ–±–æ—Ç–∞ (–º–µ–Ω—à–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

## –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è
–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç—ñ–≤

### –í—Å—ñ —Ç–µ—Å—Ç–∏
pytest

### –ó –ø–æ–∫—Ä–∏—Ç—Ç—è–º –∫–æ–¥—É
pytest --cov=app tests/

### –¢—ñ–ª—å–∫–∏ —à–≤–∏–¥–∫—ñ —Ç–µ—Å—Ç–∏
pytest -m "not slow"

### –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
pytest tests/test_search_api.py -v

### –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è API
#### –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è —ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—ó
python scripts/test_search.py

#### Bulk —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
python scripts/test_bulk_operations.py

# –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —Ç–∞ –ª–æ–≥—É–≤–∞–Ω–Ω—è
–õ–æ–≥–∏ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –≤ logs/document_search.log (JSON —Ñ–æ—Ä–º–∞—Ç):
### –ü–µ—Ä–µ–≥–ª—è–¥ –ª–æ–≥—ñ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º—É —á–∞—Å—ñ
tail -f logs/document_search.log | jq .

### –ü–æ—à—É–∫ –ø–æ–º–∏–ª–æ–∫
grep "ERROR" logs/document_search.log | jq .

### –ú–µ—Ç—Ä–∏–∫–∏
–°–∏—Å—Ç–µ–º–∞ –Ω–∞–¥–∞—î –¥–µ—Ç–∞–ª—å–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏ —á–µ—Ä–µ–∑ API:

#### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º–∏
curl http://localhost:8000/api/v1/documents/stats/detailed

#### Health check
curl http://localhost:8000/health


üîç –ü—Ä–∏–∫–ª–∞–¥–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
1. –ü–æ—à—É–∫ —Ç–µ—Ö–Ω—ñ—á–Ω–æ—ó –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—ó
pythonimport requests

response = requests.post("http://localhost:8000/api/v1/search/semantic", json={
    "query": "—Ç–µ—Ö–Ω—ñ—á–Ω—ñ –≤–∏–º–æ–≥–∏ –¥–æ –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∏",
    "limit": 5,
    "score_threshold": 0.8,
    "file_types": ["docx", "pdf"]
})

results = response.json()
for result in results["results"]:
    print(f"üìÑ {result['source_file']}")
    print(f"üéØ Score: {result['score']:.3f}")
    print(f"üìù {result['text'][:200]}...")
    print("-" * 50)

2. –ê–Ω–∞–ª—ñ–∑ —è–∫–æ—Å—Ç—ñ –ø–æ—à—É–∫—É
python# –ê–Ω–∞–ª—ñ–∑ –∑–∞–ø–∏—Ç—É –ø–µ—Ä–µ–¥ –ø–æ—à—É–∫–æ–º
response = requests.post("http://localhost:8000/api/v1/search/analyze", json={
    "query": "—ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ–π–Ω–∞ –±–µ–∑–ø–µ–∫–∞"
})

analysis = response.json()
print(f"–°–∫–ª–∞–¥–Ω—ñ—Å—Ç—å –∑–∞–ø–∏—Ç—É: {analysis['estimated_complexity']}")
print(f"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó: {analysis['recommendations']}")

3. Batch –æ–±—Ä–æ–±–∫–∞
python# –ü–µ—Ä–µ—ñ–Ω–¥–µ–∫—Å–∞—Ü—ñ—è –≤—Å—ñ—Ö –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤
response = requests.post("http://localhost:8000/api/v1/documents/index", json={
    "force_reindex": True,
    "file_types_filter": ["docx", "pdf"]
})

stats = response.json()["stats"]
print(f"–û–±—Ä–æ–±–ª–µ–Ω–æ: {stats['chunks_processed']} —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ñ–≤")
print(f"–ü—Ä–æ—ñ–Ω–¥–µ–∫—Å–æ–≤–∞–Ω–æ: {stats['chunks_indexed']} —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ñ–≤")
print(f"–ß–∞—Å –æ–±—Ä–æ–±–∫–∏: {stats['total_time_s']:.2f} —Å–µ–∫—É–Ω–¥")
üõ†Ô∏è –†–æ–∑—Ä–æ–±–∫–∞
–ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è dev —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞
bash# –ö–ª–æ–Ω—É–≤–∞–Ω–Ω—è —Ç–∞ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è
git clone https://github.com/your-org/document-search-service.git
cd document-search-service

### Dev –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ
pip install -r requirements.txt
pip install pytest black flake8 mypy

### Pre-commit hooks
pre-commit install


# –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç—É
document-search-service/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/                 # REST API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ services/            # –ë—ñ–∑–Ω–µ—Å –ª–æ–≥—ñ–∫–∞
‚îÇ   ‚îú‚îÄ‚îÄ models/              # –î–∞—Ç–∞ –º–æ–¥–µ–ª—ñ
‚îÇ   ‚îú‚îÄ‚îÄ utils/               # –£—Ç–∏–ª—ñ—Ç–∏
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è
‚îÇ   ‚îî‚îÄ‚îÄ main.py              # FastAPI –¥–æ–¥–∞—Ç–æ–∫
‚îú‚îÄ‚îÄ tests/                   # –¢–µ—Å—Ç–∏
‚îú‚îÄ‚îÄ scripts/                 # –î–æ–ø–æ–º—ñ–∂–Ω—ñ —Å–∫—Ä–∏–ø—Ç–∏
‚îú‚îÄ‚îÄ docs/                    # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è
‚îú‚îÄ‚îÄ docker-compose.yml       # Docker Compose
‚îú‚îÄ‚îÄ Dockerfile               # Docker –æ–±—Ä–∞–∑
‚îî‚îÄ‚îÄ requirements.txt         # Python –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ


## Code Style
–ü—Ä–æ–µ–∫—Ç –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î:

Black –¥–ª—è —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è –∫–æ–¥—É
Flake8 –¥–ª—è –ª—ñ–Ω—Ç—ñ–Ω–≥—É
MyPy –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ç–∏–ø—ñ–≤
Pytest –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è

# Kubernetes
Docker Production
## Build production –æ–±—Ä–∞–∑—É
docker build --target production -t document-search:latest .

## –ó–∞–ø—É—Å–∫ –∑ production –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—î—é
docker run -d \
  --name document-search \
  -p 8000:8000 \
  -v /path/to/documents:/app/documents:ro \
  -v /path/to/logs:/app/logs \
  --env-file .env.production \
  document-search:latest

## k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: document-search
spec:
  replicas: 3
  selector:
    matchLabels:
      app: document-search
  template:
    metadata:
      labels:
        app: document-search
    spec:
      containers:
      - name: document-search
        image: document-search:latest
        ports:
        - containerPort: 8000
        envFrom:
        - configMapRef:
            name: document-search-config
        volumeMounts:
        - name: documents
          mountPath: /app/documents
          readOnly: true


üë• –ê–≤—Ç–æ—Ä–∏

AntonyNest - –ü–æ—á–∞—Ç–∫–æ–≤–∞ —Ä–æ–±–æ—Ç–∞ - YourOrg